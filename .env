# System Configuration
ENV_MODE=development
ENABLE_EVALUATION=True
LOG_LEVEL=INFO
MAX_INPUT_LENGTH=1000

# Security
PATIENT_ID_SALT=changeme_random_salt_string

# Models (NVIDIA NIM)
# LLM Generation Key
NVIDIA_LLM_API_KEY=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

# Embedding Key
NVIDIA_EMBEDDING_API_KEY=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

LLM_MODEL_NAME=nvidia/llama-3.3-nemotron-super-49b-v1.5
EMBEDDING_MODEL_NAME=nvidia/nv-embedqa-e5-v5
LLM_API_URL=https://integrate.api.nvidia.com/v1

# Database Configuration
# Default to localhost for local development. Docker Compose will override this to 'http://weaviate:8080'.
WEAVIATE_URL=http://localhost:8080

# CORS (Optional override)
BACKEND_CORS_ORIGINS=["http://localhost:5173","http://localhost:3000"]